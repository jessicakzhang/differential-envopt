{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNWbyw+BtjSD9l0X6CE2qJa"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roZ4y8sr41jn",
        "outputId": "856f344a-a726-453d-b5d9-3e5f27efbb9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Google Colab - installing dependencies...\n",
            "Done with imports.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/earth2studio/data/gfs.py:120: RuntimeWarning: coroutine 'GFS._async_init' was never awaited\n",
            "  self.fs = None\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "# FourCastNet Sensitivity Analysis Script - FIXED VERSION\n",
        "# This script performs sensitivity analysis to determine how RH at a target location\n",
        "# depends on initial conditions across North America through multiple timesteps\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from matplotlib.colors import TwoSlopeNorm\n",
        "\n",
        "\"\"\"\n",
        "List of GFS model variables:\n",
        "----------\n",
        "u10m   : Zonal Wind Component at 10m [m/s]\n",
        "         East-west wind speed 10m above ground.\n",
        "v10m   : Meridional Wind Component at 10m [m/s]\n",
        "         North-south wind speed 10m above ground.\n",
        "t2m    : 2m Air Temperature [K]\n",
        "         Air temperature 2m above ground surface.\n",
        "sp     : Surface Pressure [hPa]\n",
        "         Atmospheric pressure at surface level.\n",
        "msl    : Mean Sea Level Pressure [hPa]\n",
        "         Pressure reduced to sea level.\n",
        "t850   : Temperature at 850hPa [K]\n",
        "         Air temperature at 850hPa (~1,500m altitude).\n",
        "u1000  : Zonal Wind Component at 1000hPa [m/s]\n",
        "         East-west wind speed at 1000hPa (~110m altitude).\n",
        "v1000  : Meridional Wind Component at 1000hPa [m/s]\n",
        "         North-south wind speed at 1000hPa.\n",
        "z1000  : Geopotential Height at 1000hPa [m]\n",
        "         Height of 1000hPa pressure surface above sea level.\n",
        "u850   : Zonal Wind Component at 850hPa [m/s]\n",
        "         East-west wind speed at 850hPa.\n",
        "v850   : Meridional Wind Component at 850hPa [m/s]\n",
        "         North-south wind speed at 850hPa.\n",
        "z850   : Geopotential Height at 850hPa [m]\n",
        "         Height of 850hPa pressure surface above sea level.\n",
        "u500   : Zonal Wind Component at 500hPa [m/s]\n",
        "         East-west wind speed at 500hPa (~5,600m altitude).\n",
        "v500   : Meridional Wind Component at 500hPa [m/s]\n",
        "         North-south wind speed at 500hPa.\n",
        "z500   : Geopotential Height at 500hPa [m]\n",
        "         Height of 500hPa pressure surface above sea level.\n",
        "t500   : Temperature at 500hPa [K]\n",
        "         Air temperature at 500hPa.\n",
        "z50    : Geopotential Height at 50hPa [m]\n",
        "         Height of 50hPa pressure surface (~19,300m altitude).\n",
        "r500   : Relative Humidity at 500hPa [%]\n",
        "         Relative humidity at 500hPa.\n",
        "r850   : Relative Humidity at 850hPa [%]\n",
        "         Relative humidity at 850hPa.\n",
        "tcwv   : Total Column Water Vapor [kg/m²]\n",
        "         Integrated water vapor content above the surface.\n",
        "u100m  : Zonal Wind Component at 100m [m/s]\n",
        "         East-west wind speed 100m above ground.\n",
        "v100m  : Meridional Wind Component at 100m [m/s]\n",
        "         North-south wind speed 100m above ground.\n",
        "u250   : Zonal Wind Component at 250hPa [m/s]\n",
        "         East-west wind speed at 250hPa (~10,400m altitude).\n",
        "v250   : Meridional Wind Component at 250hPa [m/s]\n",
        "         North-south wind speed at 250hPa.\n",
        "z250   : Geopotential Height at 250hPa [m]\n",
        "         Height of 250hPa pressure surface above sea level.\n",
        "t250   : Temperature at 250hPa [K]\n",
        "         Air temperature at 250hPa.\n",
        "\n",
        "Notes:\n",
        "------\n",
        "- Wind components (u/v) are in meters per second (m/s): u = east-west, v = north-south.\n",
        "- Temperatures are in Kelvin (K); can be converted to °C or °F if needed.\n",
        "- Geopotential height (z) gives the elevation of constant-pressure surfaces.\n",
        "- Pressure is in hectopascals (hPa); altitude estimates are approximate.\n",
        "- Moisture variables include relative humidity (%) and total column water vapor (kg/m²).\n",
        "\"\"\"\n",
        "\n",
        "def is_colab():\n",
        "    \"\"\"Check if code is running in Google Colab\"\"\"\n",
        "    try:\n",
        "        import google.colab\n",
        "        return True\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "if is_colab():\n",
        "    print(\"Running in Google Colab - installing dependencies...\")\n",
        "    import subprocess\n",
        "    subprocess.run(\"uv pip install earth2studio[fcn] torch numpy xarray netcdf4 loguru tqdm -q\", shell=True, check=True)\n",
        "\n",
        "import torch\n",
        "from torch.utils.checkpoint import checkpoint\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "from datetime import datetime, timedelta\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Optional\n",
        "from earth2studio.models.px import FCN\n",
        "from earth2studio.data import GFS\n",
        "import tqdm\n",
        "import types\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# Suppress DEBUG messages from earth2studio.data.gfs module\n",
        "# The library uses loguru, not standard logging\n",
        "from loguru import logger\n",
        "logger.remove()  # Remove default handler\n",
        "logger.add(lambda _: None, level=\"WARNING\")  # Only show WARNING and above\n",
        "print(\"Done with imports.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from collections import OrderedDict\n",
        "from dataclasses import dataclass, field\n",
        "import tqdm\n",
        "import types\n",
        "import os\n",
        "os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"expandable_segments:True\")\n",
        "\n",
        "def patch_model_for_gradients(model):\n",
        "    \"\"\"\n",
        "    Patch the FCN model to enable gradient computation\n",
        "    by replacing the decorated _forward method\n",
        "    \"\"\"\n",
        "    # Get the original _forward method\n",
        "    original_forward = model._forward\n",
        "\n",
        "    # If it's decorated with inference_mode, we need to unwrap it\n",
        "    if hasattr(original_forward, '__wrapped__'):\n",
        "        # Get the undecorated function\n",
        "        unwrapped_forward = original_forward.__wrapped__\n",
        "\n",
        "        # Bind it back to the model instance\n",
        "        model._forward = types.MethodType(unwrapped_forward, model)\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def model_forward_wrapper(current_state, coords, model, target_index):\n",
        "    \"\"\"Forward pass wrapper for checkpointing.\"\"\"\n",
        "    result = model(current_state, coords)\n",
        "    if isinstance(result, tuple):\n",
        "        output, _ = result\n",
        "    else:\n",
        "        output = result\n",
        "    target_contribution = output[0, 0, target_index]\n",
        "    return output, target_contribution\n",
        "\n",
        "@dataclass\n",
        "class ExperimentConfig:\n",
        "    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    batch_size: int = 1\n",
        "    num_timesteps: int = 60\n",
        "    lead_time_hours: int = 0\n",
        "    fcn_variables: list = field(default_factory=lambda: [\n",
        "        \"u10m\", \"v10m\", \"t2m\", \"sp\", \"msl\", \"t850\", \"u1000\", \"v1000\", \"z1000\",\n",
        "        \"u850\", \"v850\", \"z850\", \"u500\", \"v500\", \"z500\", \"t500\", \"z50\", \"r500\",\n",
        "        \"r850\", \"tcwv\", \"u100m\", \"v100m\", \"u250\", \"v250\", \"z250\", \"t250\"\n",
        "    ])\n",
        "    target_variable: str = 'r500'\n",
        "    lat_points: int = 720\n",
        "    lon_points: int = 1440\n",
        "    resolution: float = 0.25\n",
        "    target_lat: float = 33.4482\n",
        "    target_lon: float = -112.0777\n",
        "    perturb_std: float = 0.1  # standard deviation for Gaussian perturbations\n",
        "\n",
        "cfg = ExperimentConfig()\n",
        "\n",
        "print(f\"\\n=== SENSITIVITY ANALYSIS ===\")\n",
        "print(f\"Configuration: {cfg.num_timesteps} timesteps ({cfg.num_timesteps * 6 / 24:.1f} days) starting from {cfg.start_date}\")\n",
        "print(f\"Target location: {cfg.target_lat:.4f}°N, {cfg.target_lon:.4f}°W\")\n",
        "\n",
        "# Load model\n",
        "print(\"Loading model...\")\n",
        "device = torch.device(cfg.device)\n",
        "package = FCN.load_default_package()\n",
        "model = FCN.load_model(package).to(device).eval()\n",
        "\n",
        "if patch_model_for_gradients(model):\n",
        "    print(\"✓ Model patched for gradients\")\n",
        "else:\n",
        "    print(\"⚠ Could not patch model; gradients may fail\")\n",
        "\n",
        "target_index = cfg.fcn_variables.index(cfg.target_variable)\n",
        "\n",
        "coords_template = OrderedDict({\n",
        "    \"batch\": np.empty(cfg.batch_size),\n",
        "    \"lead_time\": np.array([np.timedelta64(cfg.lead_time_hours, \"h\")]),\n",
        "    \"variable\": np.array(cfg.fcn_variables),\n",
        "    \"lat\": np.linspace(90, -90, cfg.lat_points, endpoint=False),\n",
        "    \"lon\": np.linspace(0, 360, cfg.lon_points, endpoint=False)\n",
        "})\n",
        "\n",
        "lat_array = coords_template['lat']\n",
        "lon_array = coords_template['lon']\n",
        "target_lon_360 = cfg.target_lon % 360\n",
        "lat_idx = np.argmin(np.abs(lat_array - cfg.target_lat))\n",
        "lon_idx = np.argmin(np.abs(lon_array - target_lon_360))\n",
        "\n",
        "print(f\"Target grid idx: lat={lat_idx}, lon={lon_idx}\")\n",
        "\n",
        "# Ensemble configuration\n",
        "ensemble_size = 5\n",
        "start_dates = [dt.datetime(2024, 7, 15) + dt.timedelta(days=i) for i in range(ensemble_size)]\n",
        "# store gradients for each ensemble member\n",
        "ensemble_gradients = {var: [] for var in cfg.fcn_variables}\n",
        "\n",
        "# Ensemble loop\n",
        "for ens_idx, start_date in enumerate(start_dates, 1):\n",
        "    print(f\"\\n=== Ensemble member {ens_idx}/{ensemble_size} starting {start_date} ===\")\n",
        "\n",
        "    # Load initial state\n",
        "    data_source = GFS()\n",
        "    input_data = data_source(time=start_date, variable=cfg.fcn_variables)\n",
        "    coords = coords_template.copy()\n",
        "\n",
        "    # Convert to tensor\n",
        "    input_tensor = torch.from_numpy(input_data.to_numpy()[None]).float().to(device)\n",
        "    # apply gaussian perturbation\n",
        "    if cfg.perturb_std > 0:\n",
        "        input_tensor += torch.randn_like(input_tensor) * cfg.perturb_std\n",
        "    input_tensor.requires_grad_(True)\n",
        "\n",
        "    # forward\n",
        "    current_state = input_tensor[..., :-1, :]\n",
        "    target_sum = 0.0\n",
        "    count = 0\n",
        "    for t in tqdm.trange(cfg.num_timesteps):\n",
        "        output, target_contribution = torch.utils.checkpoint.checkpoint(\n",
        "            model_forward_wrapper,\n",
        "            current_state,\n",
        "            coords,\n",
        "            model,\n",
        "            target_index,\n",
        "            use_reentrant=False,\n",
        "        )\n",
        "        target_sum += target_contribution\n",
        "        current_state = output  # keep graph\n",
        "        count += 1\n",
        "\n",
        "    # Compute mean target contribution\n",
        "    target_mean = target_sum / cfg.num_timesteps\n",
        "\n",
        "    print(f\"\\n  Computing Sensitivity Analysis \")\n",
        "    print(f\"\\n   Computing gradients with respect to initial conditions...\")\n",
        "\n",
        "    # backpropagate to get grads wrt input tensor\n",
        "    input_tensor.grad = None\n",
        "    target_mean[lat_idx, lon_idx].backward(inputs=[input_tensor])\n",
        "\n",
        "    # Get the gradients with respect to initial conditions\n",
        "    if input_tensor.grad is not None:\n",
        "        # The gradients are with respect to the original input tensor\n",
        "        gradients = input_tensor.grad[0, 0, :, :-1, :]  # Remove batch, lead_time dims and south pole\n",
        "        print(f\"   Gradient shape: {gradients.shape}\")\n",
        "\n",
        "        for var_idx, var_name in enumerate(cfg.fcn_variables):\n",
        "            # Get gradient for this variable\n",
        "            var_grad = gradients[var_idx]\n",
        "            ensemble_gradients[var_name].append(var_grad.cpu().detach().numpy())\n",
        "\n",
        "\n",
        "    print(f\"\\n   ✓ Sensitivity analysis complete for ensemble member {ens_idx}!\")\n",
        "    print(f\"   Computed gradients for {len(ensemble_gradients)} variables\")\n",
        "\n",
        "# Average gradients over ensemble\n",
        "avg_gradients = {}\n",
        "for var_name, grads_list in ensemble_gradients.items():\n",
        "    avg_gradients[var_name] = np.mean(grads_list, axis=0)\n",
        "    print(f\"{var_name}: ensemble-avg max_abs_grad={np.abs(avg_gradients[var_name]).max():.2e}, \"\n",
        "          f\"mean_abs_grad={np.abs(avg_gradients[var_name]).mean():.2e}\")\n",
        "\n",
        "\n",
        "print(\"✓ Ensemble sensitivity analysis complete\")\n"
      ],
      "metadata": {
        "id": "iGXq3CeGZvW0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c3aad61-05f3-49a6-c092-b09de48ce1cf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...\n",
            "✓ Model patched for gradients\n",
            "Target grid idx: lat=226, lon=992\n",
            "\n",
            "=== Ensemble member 1/5 starting 2024-07-15 00:00:00 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching GFS data: 100%|██████████| 26/26 [00:01<00:00, 24.68it/s]\n",
            "100%|██████████| 60/60 [00:22<00:00,  2.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Computing Sensitivity Analysis \n",
            "\n",
            "   Computing gradients with respect to initial conditions...\n",
            "   Gradient shape: torch.Size([26, 720, 1440])\n",
            "\n",
            "   ✓ Sensitivity analysis complete for ensemble member 1!\n",
            "   Computed gradients for 26 variables\n",
            "\n",
            "=== Ensemble member 2/5 starting 2024-07-16 00:00:00 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching GFS data: 100%|██████████| 26/26 [00:01<00:00, 25.62it/s]\n",
            "100%|██████████| 60/60 [00:21<00:00,  2.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Computing Sensitivity Analysis \n",
            "\n",
            "   Computing gradients with respect to initial conditions...\n",
            "   Gradient shape: torch.Size([26, 720, 1440])\n",
            "\n",
            "   ✓ Sensitivity analysis complete for ensemble member 2!\n",
            "   Computed gradients for 26 variables\n",
            "\n",
            "=== Ensemble member 3/5 starting 2024-07-17 00:00:00 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching GFS data: 100%|██████████| 26/26 [00:01<00:00, 23.16it/s]\n",
            "100%|██████████| 60/60 [00:21<00:00,  2.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Computing Sensitivity Analysis \n",
            "\n",
            "   Computing gradients with respect to initial conditions...\n",
            "   Gradient shape: torch.Size([26, 720, 1440])\n",
            "\n",
            "   ✓ Sensitivity analysis complete for ensemble member 3!\n",
            "   Computed gradients for 26 variables\n",
            "\n",
            "=== Ensemble member 4/5 starting 2024-07-18 00:00:00 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching GFS data: 100%|██████████| 26/26 [00:01<00:00, 23.15it/s]\n",
            "100%|██████████| 60/60 [00:21<00:00,  2.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Computing Sensitivity Analysis \n",
            "\n",
            "   Computing gradients with respect to initial conditions...\n",
            "   Gradient shape: torch.Size([26, 720, 1440])\n",
            "\n",
            "   ✓ Sensitivity analysis complete for ensemble member 4!\n",
            "   Computed gradients for 26 variables\n",
            "\n",
            "=== Ensemble member 5/5 starting 2024-07-19 00:00:00 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching GFS data: 100%|██████████| 26/26 [00:01<00:00, 23.15it/s]\n",
            "100%|██████████| 60/60 [00:21<00:00,  2.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Computing Sensitivity Analysis \n",
            "\n",
            "   Computing gradients with respect to initial conditions...\n",
            "   Gradient shape: torch.Size([26, 720, 1440])\n",
            "\n",
            "   ✓ Sensitivity analysis complete for ensemble member 5!\n",
            "   Computed gradients for 26 variables\n",
            "u10m: ensemble-avg max_abs_grad=1.57e+11, mean_abs_grad=2.49e+07\n",
            "v10m: ensemble-avg max_abs_grad=2.19e+11, mean_abs_grad=2.88e+07\n",
            "t2m: ensemble-avg max_abs_grad=1.30e+11, mean_abs_grad=1.58e+07\n",
            "sp: ensemble-avg max_abs_grad=1.33e+08, mean_abs_grad=2.08e+04\n",
            "msl: ensemble-avg max_abs_grad=1.34e+09, mean_abs_grad=2.50e+05\n",
            "t850: ensemble-avg max_abs_grad=1.13e+11, mean_abs_grad=2.09e+07\n",
            "u1000: ensemble-avg max_abs_grad=2.09e+11, mean_abs_grad=2.41e+07\n",
            "v1000: ensemble-avg max_abs_grad=2.41e+11, mean_abs_grad=2.85e+07\n",
            "z1000: ensemble-avg max_abs_grad=3.05e+09, mean_abs_grad=4.61e+05\n",
            "u850: ensemble-avg max_abs_grad=3.30e+11, mean_abs_grad=2.51e+07\n",
            "v850: ensemble-avg max_abs_grad=4.58e+11, mean_abs_grad=3.16e+07\n",
            "z850: ensemble-avg max_abs_grad=3.55e+09, mean_abs_grad=6.37e+05\n",
            "u500: ensemble-avg max_abs_grad=1.23e+11, mean_abs_grad=1.55e+07\n",
            "v500: ensemble-avg max_abs_grad=1.38e+11, mean_abs_grad=2.02e+07\n",
            "z500: ensemble-avg max_abs_grad=1.27e+09, mean_abs_grad=2.98e+05\n",
            "t500: ensemble-avg max_abs_grad=7.54e+10, mean_abs_grad=1.97e+07\n",
            "z50: ensemble-avg max_abs_grad=1.40e+08, mean_abs_grad=2.82e+04\n",
            "r500: ensemble-avg max_abs_grad=1.99e+10, mean_abs_grad=5.37e+06\n",
            "r850: ensemble-avg max_abs_grad=5.13e+10, mean_abs_grad=6.57e+06\n",
            "tcwv: ensemble-avg max_abs_grad=1.80e+11, mean_abs_grad=2.35e+07\n",
            "u100m: ensemble-avg max_abs_grad=2.31e+11, mean_abs_grad=2.36e+07\n",
            "v100m: ensemble-avg max_abs_grad=3.20e+11, mean_abs_grad=2.55e+07\n",
            "u250: ensemble-avg max_abs_grad=5.81e+10, mean_abs_grad=9.61e+06\n",
            "v250: ensemble-avg max_abs_grad=5.84e+10, mean_abs_grad=1.29e+07\n",
            "z250: ensemble-avg max_abs_grad=4.38e+08, mean_abs_grad=1.12e+05\n",
            "t250: ensemble-avg max_abs_grad=9.92e+10, mean_abs_grad=2.06e+07\n",
            "✓ Ensemble sensitivity analysis complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check shape\n",
        "for var_name, grads_list in ensemble_gradients.items():\n",
        "    print(f\"{var_name}: {len(grads_list)} members, each shape {grads_list[0].shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSyAldAJGzT9",
        "outputId": "145c727a-6a5f-4890-c8fd-d80d89aaee7c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "u10m: 5 members, each shape (720, 1440)\n",
            "v10m: 5 members, each shape (720, 1440)\n",
            "t2m: 5 members, each shape (720, 1440)\n",
            "sp: 5 members, each shape (720, 1440)\n",
            "msl: 5 members, each shape (720, 1440)\n",
            "t850: 5 members, each shape (720, 1440)\n",
            "u1000: 5 members, each shape (720, 1440)\n",
            "v1000: 5 members, each shape (720, 1440)\n",
            "z1000: 5 members, each shape (720, 1440)\n",
            "u850: 5 members, each shape (720, 1440)\n",
            "v850: 5 members, each shape (720, 1440)\n",
            "z850: 5 members, each shape (720, 1440)\n",
            "u500: 5 members, each shape (720, 1440)\n",
            "v500: 5 members, each shape (720, 1440)\n",
            "z500: 5 members, each shape (720, 1440)\n",
            "t500: 5 members, each shape (720, 1440)\n",
            "z50: 5 members, each shape (720, 1440)\n",
            "r500: 5 members, each shape (720, 1440)\n",
            "r850: 5 members, each shape (720, 1440)\n",
            "tcwv: 5 members, each shape (720, 1440)\n",
            "u100m: 5 members, each shape (720, 1440)\n",
            "v100m: 5 members, each shape (720, 1440)\n",
            "u250: 5 members, each shape (720, 1440)\n",
            "v250: 5 members, each shape (720, 1440)\n",
            "z250: 5 members, each shape (720, 1440)\n",
            "t250: 5 members, each shape (720, 1440)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "13MBHp1ZIZva"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}